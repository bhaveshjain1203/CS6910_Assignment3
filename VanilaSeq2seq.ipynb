{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMIUVTL4orxQa7aoNhrkqhl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CS22M029/cs6910_assignment3/blob/main/VanilaSeq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "-7TWV91kjVJo",
        "outputId": "e960e157-b440-4f50-f366-eb7b2548d093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload hin_train.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c9203e4f-8da6-4511-af8e-79886d5f3e56\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c9203e4f-8da6-4511-af8e-79886d5f3e56\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hin_train.csv to hin_train.csv\n",
            "train:sample: ['gaderi', 'गदेरी']\n",
            "Number of training examples: 51200\n",
            "Upload hin_valid.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-24657dd4-c9ce-42ee-a0d4-30ae15deb590\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-24657dd4-c9ce-42ee-a0d4-30ae15deb590\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hin_valid.csv to hin_valid.csv\n",
            "validation:sample: ['farishte', 'फरिश्ते']\n",
            "Number of validation examples: 4096\n",
            "Upload hin_test.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-df419384-56f8-4d54-836d-929f3b781da7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-df419384-56f8-4d54-836d-929f3b781da7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hin_test.csv to hin_test.csv\n",
            "Test:sample: ['thaki', 'थकी']\n",
            "Number of Test examples: 4096\n",
            "30\n"
          ]
        }
      ],
      "source": [
        "# Import necessary packages\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as Function\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from google.colab import files \n",
        "\n",
        "# Check if CUDA is available\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "# Set the device type to CUDA if available, otherwise use CPU\n",
        "if use_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# Define constants for special cases\n",
        "Start_Symbol, End_Symbol, Unknown, Padding = 0, 1, 2, 3\n",
        "\n",
        "#Define a class for a Vocabulary that will hold mappings between characters and their indices\n",
        "class Vocabulary:\n",
        "    def __init__(self):\n",
        "        self.char2count = {}\n",
        "        self.char2index = {}\n",
        "        self.n_chars = 4\n",
        "        self.index2char = {0: \"<\", 1: \">\", 2: \"?\", 3: \".\"}\n",
        "\n",
        "    def addWord(self, word):\n",
        "        for char in word:\n",
        "            if char not in self.char2index:\n",
        "                self.char2index[char] = self.n_chars\n",
        "                self.index2char[self.n_chars] = char\n",
        "                self.char2count[char] = 1\n",
        "                self.n_chars += 1\n",
        "            else:\n",
        "                self.char2count[char] += 1\n",
        "\n",
        "\n",
        "# Define a function to prepare the data\n",
        "def prepareData(dir):\n",
        "    # Upload the CSV file\n",
        "    print(\"Upload\", dir)\n",
        "    uploaded = files.upload()\n",
        "    \n",
        "    # Read the CSV file into a DataFrame with columns \"input\" and \"target\"\n",
        "    data = pd.read_csv(next(iter(uploaded)), sep=\",\", names=[\"input\", \"target\"])\n",
        "\n",
        "\n",
        "    # Find the maximum length of input and target sequences\n",
        "    max_input_length = max([len(txt) for txt in data[\"input\"].to_list()])\n",
        "    max_target_length = max([len(txt) for txt in data[\"target\"].to_list()])\n",
        "    max_len=max(max_input_length,max_target_length)\n",
        "\n",
        "    # Create Vocabulary objects for input and output languages\n",
        "    input_lang = Vocabulary()\n",
        "    output_lang = Vocabulary()\n",
        "\n",
        "    # Create pairs of input and target sequences\n",
        "    pairs = []\n",
        "    input_list, target_list = data[\"input\"].to_list(), data[\"target\"].to_list()\n",
        "    for i in range(len(input_list)):\n",
        "        pairs.append([input_list[i], target_list[i]])\n",
        "\n",
        "    # Add words to the respective vocabularies\n",
        "    for pair in pairs:\n",
        "        input_lang.addWord(pair[0])\n",
        "        output_lang.addWord(pair[1])\n",
        "\n",
        "    # Create a dictionary containing prepared data\n",
        "    prepared_data = {\n",
        "        \"input_lang\": input_lang,\n",
        "        \"output_lang\": output_lang,\n",
        "        \"pairs\": pairs,\n",
        "        \"max_len\": max_len\n",
        "    }\n",
        "\n",
        "    return prepared_data\n",
        "\n",
        "# Define a helper function to convert a word to a tensor\n",
        "def helpTensor(lang, word, max_length):\n",
        "    index_list = []\n",
        "    for char in word:\n",
        "        if char in lang.char2index.keys():\n",
        "            index_list.append(lang.char2index[char])\n",
        "        else:\n",
        "            index_list.append(Unknown)\n",
        "    indexes = index_list\n",
        "    indexes.append(End_Symbol)\n",
        "    indexes.extend([Padding] * (max_length - len(indexes)))\n",
        "    result = torch.LongTensor(indexes)\n",
        "    if use_cuda:\n",
        "        return result.cuda()\n",
        "    else:\n",
        "        return result\n",
        "\n",
        "# Define a function to convert pairs of input and target sequences to tensors\n",
        "def MakeTensor(input_lang, output_lang, pairs, reach):\n",
        "    res = []\n",
        "    for pair in pairs:\n",
        "        # Convert input and target sequences to tensors using the helpTensor function\n",
        "        input_variable = helpTensor(input_lang, pair[0], reach)\n",
        "        target_variable = helpTensor(output_lang, pair[1], reach)\n",
        "        res.append((input_variable, target_variable))\n",
        "    return res\n",
        "\n",
        "#Encoder Class\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers_encoder, cell_type, drop_out, bi_directional):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "\n",
        "        # Initialize the EncoderRNN with the provided parameters\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers_encoder = num_layers_encoder\n",
        "        self.cell_type = cell_type\n",
        "        self.drop_out = drop_out\n",
        "        self.bi_directional = bi_directional\n",
        "\n",
        "        # Create an embedding layer\n",
        "        self.embedding = nn.Embedding(input_size, self.embedding_size)\n",
        "        self.dropout = nn.Dropout(self.drop_out)\n",
        "\n",
        "        # Create the specified cell layer (RNN, GRU, or LSTM)\n",
        "        cell_map = {\"RNN\": nn.RNN, \"GRU\": nn.GRU, \"LSTM\": nn.LSTM}\n",
        "        self.cell_layer = cell_map[self.cell_type](\n",
        "            self.embedding_size,\n",
        "            self.hidden_size,\n",
        "            num_layers=self.num_layers_encoder,\n",
        "            dropout=self.drop_out,\n",
        "            bidirectional=self.bi_directional,\n",
        "        )\n",
        "\n",
        "    def forward(self, input, batch_size, hidden):\n",
        "        # Apply dropout to the embedded input sequence\n",
        "        embedded = self.dropout(self.embedding(input).view(1, batch_size, -1))\n",
        "\n",
        "        # Pass the embedded input through the cell layer\n",
        "        output, hidden = self.cell_layer(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self, batch_size, num_layers_enc):\n",
        "        # Initialize the hidden state with zeros\n",
        "        res = torch.zeros(num_layers_enc * 2 if self.bi_directional else num_layers_enc, batch_size, self.hidden_size)\n",
        "\n",
        "        # Move the hidden state to the GPU if use_cuda is True, else return as is\n",
        "        return res.cuda() if use_cuda else res\n",
        "\n",
        "#Decoder class\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, embedding_size, hidden_size, num_layers_decoder, cell_type, drop_out, bi_directional, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers_decoder = num_layers_decoder\n",
        "        self.cell_type = cell_type\n",
        "        self.drop_out = drop_out\n",
        "        self.bi_directional = bi_directional\n",
        "\n",
        "        # Create an embedding layer\n",
        "        self.embedding = nn.Embedding(output_size, self.embedding_size)\n",
        "        self.dropout = nn.Dropout(self.drop_out)\n",
        "\n",
        "        # Create the specified cell layer (RNN, GRU, or LSTM)\n",
        "        cell_map = {\"RNN\": nn.RNN, \"GRU\": nn.GRU, \"LSTM\": nn.LSTM}\n",
        "        self.cell_layer = cell_map[self.cell_type](\n",
        "            self.embedding_size,\n",
        "            self.hidden_size,\n",
        "            num_layers=self.num_layers_decoder,\n",
        "            dropout=self.drop_out,\n",
        "            bidirectional=self.bi_directional,\n",
        "        )\n",
        "\n",
        "        # Linear layer for output\n",
        "        self.out = nn.Linear(\n",
        "            self.hidden_size * 2 if self.bi_directional else self.hidden_size,\n",
        "            output_size,\n",
        "        )\n",
        "\n",
        "        # Softmax activation\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, batch_size, hidden):\n",
        "        # Apply dropout to the embedded input sequence and pass it through the cell layer\n",
        "        output = Function.relu(self.dropout(self.embedding(input).view(1, batch_size, -1)))\n",
        "        output, hidden = self.cell_layer(output, hidden)\n",
        "\n",
        "        # Apply softmax activation to the output\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "# Function to calculate loss (if is_training then training loss else validation loss)\n",
        "def calc_loss(encoder, decoder, input_tensor, target_tensor, batch_size, encoder_optimizer, decoder_optimizer, criterion, cell_type, num_layers_enc, max_length, is_training, teacher_forcing_ratio=0.5):\n",
        "    # Initialize the encoder hidden state\n",
        "    encoder_hidden = encoder.initHidden(batch_size, num_layers_enc)\n",
        "\n",
        "    # Check if LSTM and initialize cell state\n",
        "    if cell_type == \"LSTM\":\n",
        "        encoder_cell_state = encoder.initHidden(batch_size, num_layers_enc)\n",
        "        encoder_hidden = (encoder_hidden, encoder_cell_state)\n",
        "\n",
        "    # Zero the gradients\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    # Get input and target sequence lengths\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    # Initialize loss\n",
        "    loss = 0\n",
        "\n",
        "    # Encoder forward pass\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], batch_size, encoder_hidden)\n",
        "\n",
        "    # Initialize decoder input\n",
        "    decoder_input = torch.LongTensor([Start_Symbol] * batch_size)\n",
        "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
        "\n",
        "    # Set decoder hidden state\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    # Determine if using teacher forcing\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    # Loop over target sequence\n",
        "    if is_training:\n",
        "        # Training phase\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, batch_size, decoder_hidden)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di] if use_teacher_forcing else decoder_output.argmax(dim=1)\n",
        "    else:\n",
        "        # Validation phase\n",
        "        with torch.no_grad():\n",
        "            for di in range(target_length):\n",
        "                decoder_output, decoder_hidden = decoder(decoder_input, batch_size, decoder_hidden)\n",
        "                loss += criterion(decoder_output, target_tensor[di])\n",
        "                decoder_input = decoder_output.argmax(dim=1)\n",
        "\n",
        "    # Backpropagation and optimization in training phase\n",
        "    if is_training:\n",
        "        loss.backward()\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "    # Return the average loss per target length\n",
        "    return loss.item() / target_length\n",
        "\n",
        "\n",
        "# Calculate the accuracy of the Seq2Seq model\n",
        "def accuracy(encoder, decoder, loader, batch_size, criterion, cell_type, num_layers_enc, max_length, output_lang):\n",
        "    with torch.no_grad():\n",
        "        total = 0\n",
        "        correct = 0\n",
        "\n",
        "        for batch_x, batch_y in loader:\n",
        "            # Initialize encoder hidden state\n",
        "            encoder_hidden = encoder.initHidden(batch_size, num_layers_enc)\n",
        "\n",
        "            input_variable = Variable(batch_x.transpose(0, 1))\n",
        "            target_variable = Variable(batch_y.transpose(0, 1))\n",
        "\n",
        "            # Check if LSTM and initialize cell state\n",
        "            if cell_type == \"LSTM\":\n",
        "                encoder_cell_state = encoder.initHidden(batch_size, num_layers_enc)\n",
        "                encoder_hidden = (encoder_hidden, encoder_cell_state)\n",
        "\n",
        "            input_length = input_variable.size()[0]\n",
        "            target_length = target_variable.size()[0]\n",
        "\n",
        "            output = torch.LongTensor(target_length, batch_size)\n",
        "\n",
        "            # Initialize encoder outputs\n",
        "            encoder_outputs = Variable(torch.zeros(max_length, batch_size, encoder.hidden_size))\n",
        "            encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
        "\n",
        "            # Encoder forward pass\n",
        "            for ei in range(input_length):\n",
        "                encoder_output, encoder_hidden = encoder(input_variable[ei], batch_size, encoder_hidden)\n",
        "\n",
        "            decoder_input = Variable(torch.LongTensor([Start_Symbol] * batch_size))\n",
        "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
        "\n",
        "            decoder_hidden = encoder_hidden\n",
        "\n",
        "            # Decoder forward pass\n",
        "            for di in range(target_length):\n",
        "                decoder_output, decoder_hidden = decoder(decoder_input, batch_size, decoder_hidden)\n",
        "                topv, topi = decoder_output.data.topk(1)\n",
        "                decoder_input = torch.cat(tuple(topi))\n",
        "                output[di] = torch.cat(tuple(topi))\n",
        "\n",
        "            output = output.transpose(0, 1)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            for di in range(output.size()[0]):\n",
        "                ignore = [Start_Symbol, End_Symbol, Padding]\n",
        "                sent = [output_lang.index2char[letter.item()] for letter in output[di] if letter not in ignore]\n",
        "                y = [output_lang.index2char[letter.item()] for letter in batch_y[di] if letter not in ignore]\n",
        "                if sent == y:\n",
        "                    correct += 1\n",
        "                total += 1\n",
        "\n",
        "    return (correct / total) * 100\n",
        "\n",
        "# Train and evaluate the Seq2Seq model\n",
        "def seq2seq(encoder, decoder, train_loader, val_loader, test_loader, lr, optimizer, epochs, max_length_word, num_layers_enc, output_lang):\n",
        "    max_length = max_length_word - 1\n",
        "    # Define the optimizer and criterion\n",
        "    encoder_optimizer = optim.NAdam(encoder.parameters(), lr=lr) if optimizer == \"nadam\" else optim.Adam(encoder.parameters(), lr=lr)\n",
        "    decoder_optimizer = optim.NAdam(decoder.parameters(), lr=lr) if optimizer == \"nadam\" else optim.Adam(decoder.parameters(), lr=lr)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss_total = 0\n",
        "        val_loss_total = 0\n",
        "\n",
        "        # Training phase\n",
        "        for batch_x, batch_y in train_loader:\n",
        "            batch_x = Variable(batch_x.transpose(0, 1))\n",
        "            batch_y = Variable(batch_y.transpose(0, 1))\n",
        "            # Calculate the training loss\n",
        "            loss = calc_loss(encoder, decoder, batch_x, batch_y, batch_size, encoder_optimizer, decoder_optimizer, criterion, cell_type, num_layers_enc, max_length, is_training=True)\n",
        "            train_loss_total += loss\n",
        "\n",
        "        train_loss_avg = train_loss_total / len(train_loader)\n",
        "        print(f\"Epoch: {epoch} | Train Loss: {train_loss_avg:.4f} |\", end=\"\")\n",
        "\n",
        "        # Validation phase\n",
        "        for batch_x, batch_y in val_loader:\n",
        "            batch_x = Variable(batch_x.transpose(0, 1))\n",
        "            batch_y = Variable(batch_y.transpose(0, 1))\n",
        "            # Calculate the validation loss\n",
        "            loss = calc_loss(encoder, decoder, batch_x, batch_y, batch_size, encoder_optimizer, decoder_optimizer, criterion, cell_type, num_layers_enc, max_length, is_training=False)\n",
        "            val_loss_total += loss\n",
        "\n",
        "        val_loss_avg = val_loss_total / len(val_loader)\n",
        "        print(f\"Val Loss: {val_loss_avg:.4f} |\", end=\"\")\n",
        "\n",
        "        # Calculate validation accuracy\n",
        "        val_acc = accuracy(encoder, decoder, val_loader, batch_size, criterion, cell_type, num_layers_enc, max_length, output_lang)\n",
        "        val_acc /= 100\n",
        "        print(f\"Val Accuracy: {val_acc:.4%}\")\n",
        "\n",
        "\n",
        "# Define model hyperparameters\n",
        "hidden_size = 512\n",
        "input_lang = \"eng\"\n",
        "target_lang = \"hin\"\n",
        "cell_type = \"LSTM\"\n",
        "num_layers_encoder = 3\n",
        "num_layers_decoder = 3\n",
        "drop_out = 0\n",
        "epochs = 5\n",
        "embedding_size = 64\n",
        "bi_directional = True\n",
        "batch_size = 32\n",
        "teacher_forcing_ratio = 0.5\n",
        "optimizer = \"Nadam\"\n",
        "learning_rate = 0.001 \n",
        "\n",
        "train_path = \"hin_train.csv\"\n",
        "validation_path = \"hin_valid.csv\"\n",
        "test_path = \"hin_test.csv\"\n",
        "\n",
        "# Prepare training data\n",
        "train_prepared_data = prepareData(train_path)\n",
        "input_langs, output_langs, pairs = train_prepared_data[\"input_lang\"], train_prepared_data[\"output_lang\"], train_prepared_data[\"pairs\"]\n",
        "print(\"train:sample:\", random.choice(pairs))\n",
        "print(f\"Number of training examples: {len(pairs)}\")\n",
        "max_len = train_prepared_data[\"max_len\"]\n",
        "\n",
        "# Prepare validation data\n",
        "val_prepared_data = prepareData(validation_path)\n",
        "val_pairs = val_prepared_data[\"pairs\"]\n",
        "print(\"validation:sample:\", random.choice(val_pairs))\n",
        "print(f\"Number of validation examples: {len(val_pairs)}\")\n",
        "max_len_val = val_prepared_data[\"max_len\"]\n",
        "\n",
        "# Prepare test data\n",
        "test_prepared_data = prepareData(test_path)\n",
        "test_pairs = test_prepared_data[\"pairs\"]\n",
        "print(\"Test:sample:\", random.choice(test_pairs))\n",
        "print(f\"Number of Test examples: {len(test_pairs)}\")\n",
        "\n",
        "max_len_test = test_prepared_data[\"max_len\"]\n",
        "max_len = max(max_len, max_len_val, max_len_test) + 4\n",
        "print(max_len)\n",
        "\n",
        "# Convert data to tensors and create data loaders\n",
        "pairs = MakeTensor(input_langs, output_langs, pairs, max_len)\n",
        "val_pairs = MakeTensor(input_langs, output_langs, val_pairs, max_len)\n",
        "test_pairs = MakeTensor(input_langs, output_langs, test_pairs, max_len)\n",
        "\n",
        "train_loader = DataLoader(pairs, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_pairs, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_pairs, batch_size=1, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create the encoder and decoder models\n",
        "encoder1 = EncoderRNN(input_langs.n_chars, embedding_size, hidden_size, num_layers_encoder, cell_type, drop_out, bi_directional)\n",
        "decoder1 = DecoderRNN(embedding_size, hidden_size, num_layers_encoder, cell_type, drop_out, bi_directional, output_langs.n_chars)\n",
        "print(use_cuda)\n",
        "if use_cuda:\n",
        "   encoder1, decoder1 = encoder1.cuda(), decoder1.cuda()\n",
        "\n",
        "print(\"vanilla seq2seq\")\n",
        "# Train and evaluate the Seq2Seq model\n",
        "seq2seq(encoder1, decoder1, train_loader, val_loader, test_loader, learning_rate, optimizer, epochs, max_len, num_layers_encoder, output_langs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyfWMRLipryL",
        "outputId": "f00aeb79-0fd4-433b-a73b-eb5cf59e91e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "vanilla seq2seq\n",
            "Epoch: 0 | Train Loss: 0.7430 |Val Loss: 0.3891 |Val Accuracy: 15.4785%\n",
            "Epoch: 1 | Train Loss: 0.3333 |Val Loss: 0.2972 |Val Accuracy: 29.3457%\n",
            "Epoch: 2 | Train Loss: 0.2521 |Val Loss: 0.2775 |Val Accuracy: 33.7158%\n",
            "Epoch: 3 | Train Loss: 0.2183 |Val Loss: 0.2725 |Val Accuracy: 35.5225%\n",
            "Epoch: 4 | Train Loss: 0.1868 |Val Loss: 0.2687 |Val Accuracy: 36.0352%\n"
          ]
        }
      ]
    }
  ]
}